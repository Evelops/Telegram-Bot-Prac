import telegram
import pandas as pd
import numpy as np

import asyncio
import os
from dotenv import load_dotenv
import time
import datetime

from konlpy.tag import Mecab
from gensim.models.doc2vec import Doc2Vec

import pymysql
import boto3

from sqlalchemy import create_engine, text

# env íŒŒì¼ ì—…ë¡œë“œ
load_dotenv()

access_key = os.getenv("AWS_KEY")
secret_key = os.getenv("AWS_SECRET_KEY")

# s3 ê°ì²´ ì •ì˜.
s3 = boto3.resource('s3',
                    aws_access_key_id=access_key,
                    aws_secret_access_key=secret_key)

bucket = s3.Bucket('hangle-square')
model_file = 'recsys_model/review_d2v.model'
local_model_path = 'review_d2v.model'
bucket.download_file(model_file, local_model_path)

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ DB ì—°ê²° ì •ë³´ ë¡œë“œ
DB_HOST = os.getenv("N_DB_HOST")
DB_USER = os.getenv("N_DB_USER")
DB_PASSWORD = os.getenv("N_DB_PWD")
DB_NAME = os.getenv("N_DB_NAME")
DB_PORT = os.getenv("DB_PORT")

conn = pymysql.connect(
    host=DB_HOST,
    user=DB_USER,
    password=DB_PASSWORD,
    db=DB_NAME,
    charset='utf8'
)
cur = conn.cursor()

engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}?charset=utf8mb4', echo=False)

now = datetime.datetime.now()
now_format = now.strftime('%Y-%m-%d')
print(now_format)
# ë°ì´í„° ë¡œë“œ
news_data = pd.read_sql_query("select * from News ", engine)

# ë°ì´í„° ì „ì²˜ë¦¬
news_data['document'] = news_data['title'] + ' ' + news_data['contents']
news_data['label'] = news_data['keyword'].map({'ì—°ì˜ˆ': 0, 'ìŠ¤í¬ì¸ ': 1, 'ì •ì¹˜': 2, 'êµ­ì œ': 3, 'ì‚¬íšŒ': 4, 'ë¬¸í™”': 5})
news_data = news_data.dropna(how='any')
print(len(news_data))

# mecab ê°ì²´ ì„ ì–¸
mecab = Mecab()

# í•œê¸€ìŠ¤í€˜ì–´ ë‰´ìŠ¤ ì¸ê¸° ê²€ìƒ‰ì–´ ëª©ë¡
rankingQuery = f"SELECT keyword FROM realTimeKeyword ORDER BY cnt_num DESC LIMIT 5"
cur.execute(rankingQuery)
rows = cur.fetchall()

rankings = []
for i, row in enumerate(rows):
    string_value = row[0]  # íŠœí”Œì˜ ì²« ë²ˆì§¸ ìš”ì†Œì¸ ë¬¸ìì—´ ê°’ì„ ì„ íƒí•©ë‹ˆë‹¤.
    string_value = string_value.strip('()')  # ê´„í˜¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    rank = f"{i + 1}. {string_value}"  # ìˆœìœ„ì™€ ê²€ìƒ‰ì–´ë¥¼ ê²°í•©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
    rankings.append(rank)

# êµ¬ë…ì¤‘ì¸ ìœ ì €ì˜ user_id, telegeram_id ê°’ì„ ë¶ˆëŸ¬ì˜´
subscribedUserList = "SELECT user_id, telegram_id FROM subScribeTelegramNews"
cur.execute(subscribedUserList)
subscribedListRows = cur.fetchall()
print(f"ê¸¸ì´ => {len(subscribedListRows)}")
print(f" {subscribedListRows[0]}")
print(f" {subscribedListRows[0][0]}")
print(f" {subscribedListRows[0][1]}")

subscribedList = []
# ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ìœ ì € ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥
for row in subscribedListRows:
    subscribedList.append(list(row))

print(subscribedList)


# ìœ ì € ì•„ì´ë”” ë³„ ì¶”ì²œ ë‰´ìŠ¤ë¥¼ ì¶”ì¶œí•˜ëŠ” ë¡œì§
def getRecNews(user_id, telegram_id):
    print(f'USERID => {user_id}, TELEGRAMID => {telegram_id}')
    # ìœ ì €ê°€ í´ë¦­í•œ ì •ë³´ ë¡œê·¸ë¥¼ ì¶”ì¶œ
    query = f"SELECT idx FROM Click_News_Info WHERE user_id = {user_id}"
    result = conn.execute(text(query))

    if (result.rowcount == 0):
        # Doc2Vec ëª¨ë¸ ë¡œë“œ
        model = Doc2Vec.load('review_d2v.model')

        # ìœ ì €ì˜ ê´€ì‹¬ë¶„ì•¼ í™œìš©í•´ì„œ ë¿Œë ¤ì£¼ê¸° (ì¼ë‹¨ì€ ì²« ì…ì¥ì¸ ê²½ìš°)
        query = f"SELECT topics FROM Preferred_Topics WHERE user_id = {user_id}"
        result = conn.execute(text(query))

        row = result.fetchone()

        if row is not None:
            keyword_string = row[0]

            # ìœ ì €ê°€ ë“±ë¡í•œ ê´€ì‹¬ë¶„ì•¼ ë°°ì—´ë¡œ ë³€í™˜
        keywords = keyword_string.split(',')

        # ë°°ì—´ë¡œ ë°›ì•„ì˜¨ í‚¤ì›Œë“œ í˜•íƒœì†Œ ë¶„ì„í•´ì„œ ë²¡í„° ì¶”ì¶œ
        keyword_vectors = []
        for keyword in keywords:
            keyword_vectors.append(model.infer_vector(mecab.morphs(keyword)))

        keyword_vector = np.mean(keyword_vectors, axis=0)

        # ëª¨ë“  ë¬¸ì„œì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        doc_vectors = [model.dv[str(i)] for i in range(len(model.dv))]
        # numpy ëª¨ë“ˆì˜ np.dot() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµëœ ëª¨ë“  ë¬¸ì„œ ë²¡í„° + ì…ë ¥ëœ í‚¤ì›Œë“œê°„ ë‚´ì  ê³„ì‚°
        similarities = np.dot(doc_vectors, keyword_vector)
        top_n_indices = np.argsort(similarities)[::-1][:5]
        recommended_documents = pd.DataFrame(news_data.iloc[top_n_indices])
        values = recommended_documents['idx'].tolist()
        print(values)
    else:
        # Doc2Vec ëª¨ë¸ ë¡œë“œ
        model = Doc2Vec.load('review_d2v.model')

        # news_data2 ë°ì´í„° ë¡œë“œ (ìœ ì € í´ë¦­í•œ ë‰´ìŠ¤ë“¤)
        news_data2 = pd.read_sql_query(f"select * from Click_News_Info where user_id = {user_id}", conn)

        # ë°ì´í„° ì „ì²˜ë¦¬
        news_data2['document'] = news_data2['title'] + ' ' + news_data2['contents']
        news_data2 = news_data2.dropna(how='any')

        # news_data2 ë°ì´í„°ë¥¼ ë²¡í„°í™”
        news_data2_vectors = [model.infer_vector(mecab.morphs(doc)) for doc in news_data2['document']]

        # ë°°ì—´ë¡œ ë°›ì•„ì˜¨ news_data2 ë²¡í„°ì™€ ëª¨ë“  news_data ë²¡í„°ê°„ ë‚´ì  ê³„ì‚°
        similarity_matrix = np.dot(news_data2_vectors, np.array([model.dv[str(i)] for i in range(len(model.dv))]).T)

        # ìƒìœ„ n(5)ê°œ ë¬¸ì„œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
        top_n_indices = np.argsort(similarity_matrix, axis=1)[:, ::-1][:, :5]

        # top_n_indices ë°°ì—´ì—ì„œ news_dataì˜ ì¸ë±ìŠ¤ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ì¸ë±ìŠ¤ë¥¼ í•„í„°ë§í•˜ì—¬ ì œê±°
        top_n_indices = [np.intersect1d(x, news_data.index) for x in top_n_indices]

        values = [news_data.iloc[top_n_indices[i]]['idx'].tolist() for i in range(len(news_data2))]
        print(values)

    return "tq"


# í† í° & id ì„¤ì •
token = os.getenv("TOEKN")
chat_id = os.getenv("CHAT_ID")

# telegram token define
bot = telegram.Bot(token=token)

# Markdown-formatted ë¬¸ìì—´ ìƒì„±
msg = (
    "*[[2023-06-16] HS NEWS ì•Œë¦¼ë´‡ ì…ë‹ˆë‹¤]*\n"
    "-----------------------------------------\n"
    "*í•œê¸€ìŠ¤í€˜ì–´ ì¸ê¸° ê²€ìƒ‰ì–´ ìˆœìœ„* \n"
    f"{' '.join(rankings)}\n"
    "-----------------------------------------\n"
    "*ìœ ì €ë‹˜ì„ ìœ„í•œ ì¶”ì²œ ë‰´ìŠ¤*\n\n"
    "1. 'ë§¨ìœ ? ë®Œí—¨?' ê¹€ë¯¼ì¬ ëª¸ê°’ ë˜ ìƒìŠ¹! '695ì–µâ†’835ì–µ', 'ì†í¥ë¯¼ê³¼ ê³µë™ 1ìœ„' ...\n"
    "\n"
    "2. [ì†ë³´] ë°”ì´ì—ë¥¸ ë®Œí—¨, ê¹€ë¯¼ì¬ ì´ì ë£Œ '1000ì–µ' ìœë‹¤â€¦ë°”ì´ì•„ì›ƒ 'ìµœìƒìœ„ê¶Œ' ì•¡ìˆ˜ ì§€...\n"
    "-----------------------------------------\n"
    "ğŸ‘‰ ì„œë¹„ìŠ¤ ë°”ë¡œê°€ê¸°\n"
    "[ë°”ë¡œê°€ê¸°](https://www.hangeulsquare.com/news/)\n"
)


# v20 ì´í›„ ë©”ì‹œì§€ ì „ì†¡ í•¨ìˆ˜ ë¹„ë™ê¸°ë¡œ ì •ì˜ ë˜ì—ˆê¸°ì— ë³„ë„ì˜ asyncio ëª¨ë“ˆì„ ì¶”ê°€í•´ì„œ ì ìš©
async def send_message():
    # ë¦¬ìŠ¤íŠ¸ì—ì„œ user_id, telegram_id ê°’ì„ rowì—ì„œ ì¶”ì¶œ
    for row in subscribedList:
        user_id, telegram_id = row
        print(f"User ID: {user_id}, Telegram ID: {telegram_id}")
        # ìœ ì €ë³„ ë§ì¶¤ ì¶”ì²œ ë°ì´í„°ë¥¼ ì¶”ì¶œ í›„ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì „ì†¡
        # getRecNews(user_id,telegram_id)
        print(f'USERID => {user_id}, TELEGRAMID => {telegram_id}')
        # ìœ ì €ê°€ í´ë¦­í•œ ì •ë³´ ë¡œê·¸ë¥¼ ì¶”ì¶œ
        query = f"SELECT idx FROM Click_News_Info WHERE user_id = {user_id}"
        result = cur.execute(query)
        print(f'result => {result}')
        print(f'result => {cur.rowcount}')

        if (cur.rowcount == 0):
            print('ìœ ì €ê°€ í´ë¦­í•œ ë¡œê·¸ê°€ ì—†ìŒ')
            # Doc2Vec ëª¨ë¸ ë¡œë“œ
            model = Doc2Vec.load('review_d2v.model')
            # ìœ ì €ì˜ ê´€ì‹¬ë¶„ì•¼ í™œìš©í•´ì„œ ë¿Œë ¤ì£¼ê¸° (ì¼ë‹¨ì€ ì²« ì…ì¥ì¸ ê²½ìš°)
            query = f"SELECT topics FROM Preferred_Topics WHERE user_id = {user_id}"
            # result = cur.execute(query)
            # row = result.fetchone()
            cur.execute(query)
            row = cur.fetchone()
            if row is not None:
                keyword_string = row[0]
                # ìœ ì €ê°€ ë“±ë¡í•œ ê´€ì‹¬ë¶„ì•¼ ë°°ì—´ë¡œ ë³€í™˜
            keywords = keyword_string.split(',')
            # ë°°ì—´ë¡œ ë°›ì•„ì˜¨ í‚¤ì›Œë“œ í˜•íƒœì†Œ ë¶„ì„í•´ì„œ ë²¡í„° ì¶”ì¶œ
            keyword_vectors = []
            for keyword in keywords:
                keyword_vectors.append(model.infer_vector(mecab.morphs(keyword)))
            keyword_vector = np.mean(keyword_vectors, axis=0)
            # ëª¨ë“  ë¬¸ì„œì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
            doc_vectors = [model.dv[str(i)] for i in range(len(model.dv))]
            # numpy ëª¨ë“ˆì˜ np.dot() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµëœ ëª¨ë“  ë¬¸ì„œ ë²¡í„° + ì…ë ¥ëœ í‚¤ì›Œë“œê°„ ë‚´ì  ê³„ì‚°
            similarities = np.dot(doc_vectors, keyword_vector)
            top_n_indices = np.argsort(similarities)[::-1][:5]
            recommended_documents = pd.DataFrame(news_data.iloc[top_n_indices])
            values = recommended_documents['title'].tolist()

            msg = (
                f"*[[{now_format}] HS NEWS ì•Œë¦¼ë´‡ ì…ë‹ˆë‹¤]*\n"
                "-----------------------------------------\n"
                "*ğŸ† í•œê¸€ìŠ¤í€˜ì–´ ì¸ê¸° ê²€ìƒ‰ì–´ ìˆœìœ„* \n"
                f"{' '.join(rankings)}\n"
                "-----------------------------------------\n"
                "*ğŸ“Œ ìœ ì €ë‹˜ì„ ìœ„í•œ ì¶”ì²œ ë‰´ìŠ¤*\n\n")
            for i, value in enumerate(values[:5], 1):
                msg += f"{i}. {value}\n\n"

            msg += (
                "-----------------------------------------\n"
                "ğŸ‘‰ ì„œë¹„ìŠ¤ ë°”ë¡œê°€ê¸°\n"
                "[ë°”ë¡œê°€ê¸°](https://www.hangeulsquare.com/news/)\n")
            print(msg)
            await bot.sendMessage(chat_id=chat_id, text=msg, parse_mode='Markdown')
        else:
            print('ìœ ì €ê°€ í´ë¦­í•œ ë¡œê·¸ê°€ ìˆìŒ')
            # Doc2Vec ëª¨ë¸ ë¡œë“œ
            model = Doc2Vec.load('review_d2v.model')

            # news_data2 ë°ì´í„° ë¡œë“œ (ìœ ì € í´ë¦­í•œ ë‰´ìŠ¤ë“¤)
            news_data2 = pd.read_sql_query(f"select * from Click_News_Info where user_id = {user_id}", conn)

            # ë°ì´í„° ì „ì²˜ë¦¬
            news_data2['document'] = news_data2['title'] + ' ' + news_data2['contents']
            news_data2 = news_data2.dropna(how='any')

            # news_data2 ë°ì´í„°ë¥¼ ë²¡í„°í™”
            news_data2_vectors = [model.infer_vector(mecab.morphs(doc)) for doc in news_data2['document']]

            # ë°°ì—´ë¡œ ë°›ì•„ì˜¨ news_data2 ë²¡í„°ì™€ ëª¨ë“  news_data ë²¡í„°ê°„ ë‚´ì  ê³„ì‚°
            similarity_matrix = np.dot(news_data2_vectors, np.array([model.dv[str(i)] for i in range(len(model.dv))]).T)

            # ìƒìœ„ n(5)ê°œ ë¬¸ì„œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
            top_n_indices = np.argsort(similarity_matrix, axis=1)[:, ::-1][:, :5]

            # top_n_indices ë°°ì—´ì—ì„œ news_dataì˜ ì¸ë±ìŠ¤ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ì¸ë±ìŠ¤ë¥¼ í•„í„°ë§í•˜ì—¬ ì œê±°
            top_n_indices = [np.intersect1d(x, news_data.index) for x in top_n_indices]

            values = [news_data.iloc[top_n_indices[i]]['title'].tolist() for i in range(len(news_data2))]
            # Markdown-formatted ë¬¸ìì—´ ìƒì„±
            msg = (
                f"*[[{now_format}] HS NEWS ì•Œë¦¼ë´‡ ì…ë‹ˆë‹¤]*\n"
                "-----------------------------------------\n"
                "*ğŸ† í•œê¸€ìŠ¤í€˜ì–´ ì¸ê¸° ê²€ìƒ‰ì–´ ìˆœìœ„* \n"
                f"{' '.join(rankings)}\n"
                "-----------------------------------------\n"
                "*ğŸ“Œ ìœ ì €ë‹˜ì„ ìœ„í•œ ì¶”ì²œ ë‰´ìŠ¤*\n\n"
                f"1. {values[0][0]} \n"
                "\n"
                f"2. {values[0][1]} \n"
                "\n"
                f"3. {values[0][2]} \n"
                "\n"
                f"4. {values[0][3]} \n"
                "\n"
                f"5. {values[0][4]} \n"
                "-----------------------------------------\n"
                "ğŸ‘‰ ì„œë¹„ìŠ¤ ë°”ë¡œê°€ê¸°\n"
                "[ë°”ë¡œê°€ê¸°](https://www.hangeulsquare.com/news/)\n")
            await bot.sendMessage(chat_id=chat_id, text=msg, parse_mode='Markdown')


start = time.time()
asyncio.run(send_message())
end = time.time() - start
# connection ì¢…ë£Œ
conn.close()

print(end)  # ì´ ê±¸ë¦° ì‹œê°„ í™•ì¸
